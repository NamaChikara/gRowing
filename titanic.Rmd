---
title: "titanic"
author: "ZackBarry"
date: "8/17/2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load libraries.
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
library(DataExplorer)
library(mice)
library(parsnip) # API for rpart() and others, install_github("tidymodels/parsnip")
library(recipes)
library(ranger)
library(rsample)

complete <- mice::complete

# Read in data.
train <- read_csv("Data/titanic/train.csv")
test <- read_csv("Data/titanic/test.csv")
```

## Explore the data using DataExplorer

First, let's see what type of data we're dealing with:
```{r}
plot_intro(train)
```
The majority of the columns contain continuous data and 79.5% of the
rows have at least one missing value. Let's check which columns are
missing data:
```{r}
DataExplorer::plot_missing(train)
```
A large majority of the `Cabin` observations are missing, so we will not attempt to
impute the missing values. Since `Embarked` and `Age` are missing in far fewer
instances, we will impute them using the `MICE` package below.

Finally, let's get a sense of the distribution of our categorical and
continuous data.
```{r}
DataExplorer::plot_bar(train)
```
The response variable, `Survived`, is well balanced, and each of `Sex`
and `Embarked` have a small set of values.  Since `Name` and `Ticket`
have so many categories we will look into grouping their values when
we do feature selection below.

Next, the continuous data:
```{r}
plot_histogram(train)
```
We see that `Pclass` should be treated as categorical data.
`SibSp` and `Parch` could be binned into `SmallFamily`, `MediumFamily`, and `LargeFamily`, and it may be helpful to bin `Fare`.
`PassengerId` seems unlikely to have any relationship with whether or not that passenger survived. 
Let's check the class-specific distribution of `PassengerId`:
```{r}
ggplot(train, aes(x = PassengerId)) + 
  geom_histogram() + 
  facet_wrap(~Survived)
```
It looks like we can safely drop `PassengerId`.
```{r}
train <- select(train, -PassengerId)
```


## Mutate data

Before imputing the missing values for `Embarked` and `Age`, we will
look at grouping `Name` and `Ticket`.
```{r}
head(train$Name)
```
It looks like each name is of the form `Last, Title. First...`. Two options
present themselves: 1) Extract passenger titles and group accordingly, 
2) Extract last names and match families together.  We will start by examining
the titles.

Use `stringr::str_match()` to extract each title, assuming each title is located after a comma and is ended by a period.
```{r}
train$Title <- str_match(train$Name, ",\\s?([a-zA-Z\\s]+).")[, 2]
train <- select(train, -Name)

plot_bar(train$Title)
```
We will keep `Mr`, `Miss`, `Mrs`, `Master` as is -- the others will be joined to one of the former based on gender; if the title is indicative of a profession, that person will be grouped as `titled`.
```{r}
train <- train %>%
  mutate(Title = tolower(Title)) %>%
  mutate(Title = ifelse(str_detect(Title, "dr|rev|major|col|capt|jonkheer"), "titled",
                        ifelse(str_detect(Title, "miss|mlle|ms|lady"), "miss",
                               ifelse(str_detect(Title, "mrs|mme|countess"), "mrs", 
                                      ifelse(str_detect(Title, "mr|don|sir|master"), "mr",
                                                        "unknown")))))

plot_bar(select(train, Title))
```

Now we can group `Ticket`. The logic behind this grouping is that decreasing the
variance of `Ticket` will reduce the risk of overfitting the model to the test 
data.  Of course, the trade of is that the bias will increase so we'll need to
perform some form of cross-validation to see if the binning is an improvement.
To support this need we'll create a seperate column `TicketBinned` and compare model
performance with it included as the ticket variable or `TicketNumber` as the ticket
variable.  This comparison will be done in the feature selection section.

Some tickets numbersare preceeded by letters, but only
230 of the observations have this extra information:
```{r}
train %>%
  mutate(TicketType = as.numeric(Ticket)) %>%
  filter(is.na(TicketType)) %>% 
  select(Ticket)
```
We will extract the numbers and work with them only.
```{r}
train$TicketNumber <- as.numeric(str_extract(train$Ticket, "[0-9]+$"))

train[is.na(train$TicketNumber),]
```
4 passengers had tickets which did not include numbers -- we will impute their
ticket value by calculating the average ticket value.
```{r}
train <- train %>%
  mutate(TicketNumber = ifelse(is.na(TicketNumber), mean(train$TicketNumber, na.rm = T), TicketNumber)) %>%
  select(-Ticket)
```

Now, let's determine whether or not to bin `TicketNumber` by looking at a histogram 
of the values:
```{r}
train %>%
  ggplot(aes(x = TicketNumber)) +
  geom_histogram()
```
We clearly have a group of tickets with very high values, but it is
difficult to see the distrubution of the the lower value
tickets. Let's exclude the larger ticket values for the next histogram:
```{r}
train %>%
  filter(TicketNumber <= 1e6) %>%
  ggplot(aes(x = TicketNumber)) +
  geom_histogram()
```
No we see that there is a group of ticket values for each interval
from $[i\times 10^5, (i+1)\times 10^5)$, $0\leq i\leq 3$, but it is not clear that
binning the ticket numbers would improve the feature's importance in the model.
We will leave them be for now.

Lastly, we will use the `SibSp` and `Parch` columns to infer the size of a 
passenger's family.  The logic here is that an individual traveling alone may
have a higher survival chance since they would not be responsible for any 
others.  Large families may have a worse survival chance.  Recall that
`SipSp` is the number of siblings/spouses aboard the Titanic and `Parch` is
the number of parents/children aboard. We will 

```{r}
train <- train %>%
  mutate(Family_Size = ifelse(SibSp + Parch == 0, "Singleton",
                              ifelse(SibSp + Parch <= 4, "Small_Family",
                                     "Large_Family")))
```

## Handle missing data

Since 77.1% of the `Cabin` observations are missing, we will not impute the
missing values but will mark them as such. Each `Cabin` value contains a concatenation of
letter and number combinations of the form "AXX BYY".  We will drop the numbers
and replace the `Cabin` value with first letter that appears.
```{r}
train <- train %>%
  mutate(Letters = str_extract_all(Cabin, "^[A-Z]")) %>% # "^" matches the start of the string
  rowwise() %>%
  mutate(Cabin_Letter = Letters[[1]]) %>%
  ungroup() %>%  # rowwise() groups by row
  mutate(Cabin_Letter = ifelse(is.na(Cabin_Letter), "Unknown", Cabin_Letter)) %>%
  select(-c(Cabin, Letters))
```
Let's see what the counts of each letter are for those who survived and those that
didn't:
```{r}
train %>%
  ggplot(aes(x = Cabin_Letter, fill = as.factor(Survived))) +
  geom_bar(stat = "count", position = position_dodge())
```
An unknown cabin record is the most common for both groups, but it 
appears as if those who didn't survive are most likely to have an unknown cabin.

`Embarked` is missing in 2 observations and `Age` is missing
in 177. We'll simply replace the missing `Embarked` values with the 
most often observed value; `Age` we will impute with the `MICE` package.
```{r}
train$Embarked[is.na(train$Embarked)] <- count(train, Embarked, sort = T)[1,]$Embarked
```

Before using the `MICE` package, we will encode the categorical data in the training set - otherwise those predictors will not be used for filling in the missing data.
To do this, we will use the `recipes` package.
This package streamlines the process by which data is prepped for data
analysis.
```{r}
dummy_recipe <- recipe(Survived ~ ., data = train) %>%
  step_dummy(Embarked, Title, Cabin_Letter) %>%
  prep(training = train, retain = T)

summary(dummy_recipe)
```
The `recipe()` step specifies which variables are predictors and which
are responses for the provided data set.
`step_dummy()` converts the indicted character or factor variables into
binary model terms. 
Finally, `prep()` generates the metadata to actually do the data preparation.
Specifying `retain = T` allows us to prepare (apply) the recipe without
resupplying the data set. This is only helpful if the original data set
used to train the recipe is the same data to be processed.
Since we set this parameter, we can call `juice()` to create the
processed data.
```{r}
train_encoded <- juice(dummy_recipe)
glimpse(train_encoded)
```
Instead of the variable `Title` with 4 responses, `mr`, `mrs`, `titled`,
and `miss`, our data now has three variables `Title_mr`, `Title_mrs`, and
`Title_titled`. If an observation had a `Title` value of `mr`, `mrs`, or
`titled`, the respective `Title_x` has a value of `1`. If an observation
had a `Title` value of `miss`, each `Title_x` is `0`. Similarly for `Embarked`,
`Cabin`, and `Family_Size`.
```{r}
train_imputed <- mice(data = train_encoded, maxit = 50, printFlag = FALSE)
head(train_imputed$imp$Age)
```


## Model training

Before training our Random Forest model, we'll combine all of the preprocessing 
steps above (including `Age` imputation) into a recipe so that we can quickly
prepare subsets of the training data for cross validation.
```{r}
create_features_titanic <- function(data) {
  
  data <- data %>%
    mutate(Pclass = as.factor(Pclass)) %>% # needs to be factor to dummy encode
    mutate(Suvived = as.factor(Survived)) # needs to be factor to classify by RF
    
  # Extract information from unique variables.
  data <- data %>%
    mutate(
      Title = str_match(Name, ",\\s?([a-zA-Z\\s]+).")[, 2],
      Title = tolower(Title), 
      Title = ifelse(str_detect(Title, "dr|rev|major|col|capt|jonkheer|don|sir|master"), "titled",
                          ifelse(str_detect(Title, "miss|mlle|ms|lady"), "miss",
                                 ifelse(str_detect(Title, "mrs|mme|countess"), "mrs", 
                                        ifelse(str_detect(Title, "mr"), "mr",
                                                          "unknown")))),
      TicketNumber = as.numeric(str_extract(Ticket, "[0-9]+$"))
   ) %>%
   mutate(Letters = str_extract_all(Cabin, "^[A-Z]")) %>% 
   rowwise() %>%
   mutate(Cabin_Letter = Letters[[1]]) %>%
   ungroup() %>%
   mutate(Cabin_Letter = ifelse(is.na(Cabin_Letter), "Unknown", "Known")) %>% 
   select(-c(Cabin, Letters))
  
  # Keep only a subset of the predictor variables.
  data %>%
    select(
      PassengerId,
      Survived,
      Pclass,
      Sex,
      Age,
      Fare,
      Embarked,
      Title,
      Cabin_Letter,
      TicketNumber,
      Parch,
      SibSp
    )
}

impute_missing_titanic <- function(data) {
  # Create dummy variables for factor columns.
  #   Note: the training step is only important to do outside of the loop if 
  #         steps in the recipe have the potential to change based on the data
  #         set.  An example would be selecting a column to remove based on 
  #         near-zero variance.  In this case, we are simply creating dummy 
  #         variables so the recipe can be trained and juiced within this
  #         preproccessing function while treating all data sets consistently.
  
  # Apply simple imputations and fill in missing dependent features.
  data <- data %>%
    mutate(
      TicketNumber = ifelse(is.na(TicketNumber), mean(TicketNumber, na.rm = T), TicketNumber),
      TicketBinned = round(TicketNumber / 1e5, 0),
      Embarked = ifelse(is.na(Embarked), count(., Embarked, sort = T)[1,]$Embarked, Embarked)
    ) %>%
    select(-TicketNumber)
  
  # Impute 'Age' using MICE.
  mice(data, maxit = 50, printFlag = FALSE)
}

prep_titanic <- function(data, trained_recipe) {
  
  data <- data %>%
    create_features_titanic() %>%
    impute_missing_titanic()
  
  lapply(seq(1:data$m), function(x) { complete(data, x) %>% bake(trained_recipe, .) })
  
}

model_titanic <- function(data, mtry, trees, min_n) {
  
  data <- data %>% mutate(Survived = as.factor(Survived))
  
  rand_forest(mode = "classification", mtry = mtry, trees = trees, min_n = min_n) %>%
      set_engine("ranger") %>%
      fit(Survived ~ . - PassengerId, data = data)
  
}

params <- tidyr::crossing(
  mtry = seq(4, 5),
  trees = seq(150, 200, 50),
  min_n = seq(10, 15, by = 5)
)

  train_prepped <- vfold_data$splits[[i]] %>%
    analysis() %>%
    prep_titanic()

  test_prepped <- vfold_data$splits[[i]] %>%
    assessment() %>%
    prep_titanic()
  
  # Each element of this list contains a list of models for each imputed set
  models <- lapply(
    seq(1, nrow(params)),
    function(x) {
      mapply(
        model_titanic,
        data = train_prepped,
        mtry = params$mtry[x],
        trees = params$trees[x],
        min_n = params$min_n[x],
        SIMPLIFY = FALSE
      )
    }
  )
  
  results <- lapply(
    seq(1, length(models)),
    function(param_set) {
      lapply(
        seq(1, length(test_prepped)),
        function(test_no) {
          lapply(
            seq(1, length(models[[param_set]])),
            function(train_no) {
              models[[param_set]][[train_no]] %>%
                predict(new_data = test_prepped[[test_no]]) %>%
                mutate(PassengerId = test_prepped[[test_no]]$PassengerId) %>%
                rename(predicted = .pred_class)
            }
          ) %>%
            bind_rows() %>%
            group_by(PassengerId) %>%
            summarise(predicted = Mode(predicted))
        }
      ) %>%
        bind_rows() %>%
        group_by(PassengerId) %>%
        summarise(predicted = Mode(predicted)) %>%
        mutate(
          mtry = params$mtry[param_set],
          trees = params$trees[param_set],
          min_n = params$min_n[param_set]
        )
    }
  )
  
  true_result <- test_prepped[[1]]$Survived
  
  error <- lapply(
    seq(1, length(results)),
    function(x) {
      data.frame(
        error = mean(results[[x]]$predicted != true_result),
        mtry = results[[x]]$mtry[1],
        trees = results[[x]]$trees[1],
        min_n = results[[x]]$min_n[1],
        fold = fold
      )
    }
  ) %>%
    bind_rows()
  
  if (is.null(error_df)) {
    error_df <- error
  } else {
    error_df <- rbind(error_df, error)
  }
  
  
  # 6 times slower:
  # for (i in 1:length(models)) {
  #   for (j in 1:length(models[[i]])) {
  #     for (k in 1:length(test_prepped)) {
  #       models[[i]][[j]] %>%
  #         predict(new_data = test_prepped[[k]]) %>%
  #         bind_cols(test_prepped[[k]] %>% select(PassengerId)) %>%
  #         rename(predicted = .pred_class)
  #     }
  #   }
  # }
```

Do do cross-validation, we'll use the `rsample` package and its functions
`vfold_cv`, `analysis` and `assessment`.  `vfold_cv` is used to divide a 
data set into $v$ "folds" of equal size.  For 10-fold cv, each fold is 
approximately $1/10$ the size of the original data set.  The relative
compliment of each fold is used to train the model; an error statistic such
as RMSE is calculated by applying that model to the hold out fold.
To access a training set, `analysis()` is used; to access a hold out set, 
`assessment()` is used.

Now the order of steps gets a bit complicated here.  For each training fold, 
we'll need to preprocess both it and its complimentary validation set.  This 
step includes imputing the missing `Age` values with the MICE package.  To get
the best results, we'll calculate 5 separate imputations of `Age` and aggregrate 
the results.  These multiple imputations will result in 5 training and 5
validation sets, each with potentially different values for `Age`. The 5
training sets will be used to generate 5 models.  Each of the 5 validation sets
will be fit to each of the 5 models, with the most common result being chosen
as the prediction for the 5 validation sets.  Finally, the most common results of 
the 5 validation sets will be aggregated by selecting the most common result amongst
themselves.


```{r}
mice_rf <- function(train_imputed, mtry, trees, min_n, trained_recipe) {
  # train_imputed: A mice object containing train_imputed$m imputed data sets.
  
  models <- list()
  
  for (i in 1:train_imputed$m) {
    train_imputed_i <- complete(train_imputed, i) %>%
      bake(trained_recipe, .) %>%
      mutate(Survived = as.factor(Survived))
    
    random_forest_i <- rand_forest(mode = "classification", mtry = mtry, trees = trees, min_n = min_n) %>%
      set_engine("ranger") %>%
      fit(Survived ~ . - PassengerId, data = train_imputed_i)
    
    models[[i]] <- random_forest_i
  }
  
  return(models)
}

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

ranked_choice <- function(test, models) {
  # test: A single data set, already preprocessed with a column "id".
  # models: A list of models which can be used via predict().
  
  # returns:  id | predicted
  
  predictions <- NULL
  
  for (i in 1:length(models)) {
    
    predictions_i <- models[[i]] %>%
      predict(new_data = test) %>%
      bind_cols(test %>% select(PassengerId)) %>%
      rename(predicted = .pred_class)
    
    if (is.null(predictions)) {
      predictions <- predictions_i
    } else {
      predictions <- rbind(predictions, predictions_i)
    }
    
  }
  
  # predict() returns a factor column instead of a numeric one; convert back
  # before calling Mode()
  predictions %>%
    mutate(predicted = as.numeric(levels(predicted))[predicted]) %>%
    group_by(PassengerId) %>%
    summarise(predicted = Mode(predicted))
}

# trees: 10 - 100
err_rand_forest <- function(test_imputed, models, trained_recipe) {
  # cv_data: An object from rsample from which the training set can be retrieved
  #          via analysis(cv_data) and the test set via assessment(cv_data).
  
  result <- NULL
  
  for (i in 1:test_imputed$m) {
    test_i <- complete(test_imputed, i) %>%
      bake(trained_recipe, .)
    result_i <- ranked_choice(test_i, models)
    
    if (is.null(result)) {
      result <- result_i
    } else {
      result <- rbind(result, result_i)
    }
  }
  
  ranked_choice_result <- result %>%
    group_by(PassengerId) %>%
    summarise(predicted = Mode(predicted)) 
  
  true_result <- complete(test, 1)
  
  mean(ranked_choice_result$predicted != true_result$Survived)
}

fit_predict_error <- function(train_imputed, test_imputed, mtry, trees, min_n, trained_recipe) {
  
  models <- mice_rf(train_imputed, mtry, trees, min_n, trained_recipe)
  
  error <- err_rand_forest(test_imputed, models, trained_recipe)
  
  print(paste(error, mtry, trees, min_n))
  
  return(data.frame(error = error, mtry = mtry, trees = trees, min_n = min_n))
}
```

```{r}
train <- read_csv("Data/titanic/train.csv")

train_prepped <- prep_titanic(train)

trained_recipe <- recipe(Survived ~ ., data = train_prepped) %>%
    step_dummy(Embarked, Title, Cabin_Letter, Pclass, Sex) %>%
    prep(training = train_prepped)

test_recipe <- train_prepped %>%
  mutate(Pclass = as.factor(Pclass)) %>%
  recipe(Survived ~ ., data = .) %>%
  step_dummy(Embarked, Title, Sex, Pclass) %>%
  prep(training = mutate(train_prepped, Pclass = as.factor(Pclass)))

vfold_data <- vfold_cv(train, v = 10)

params <- tidyr::crossing(
  mtry = seq(1, 8),
  trees = seq(50, 500, 50),
  min_n = seq(5, 50, by = 5)
)

params_test <- tidyr::crossing(
  mtry = seq(4, 5),
  trees = seq(150, 200, 50),
  min_n = seq(10, 20, by = 5)
)

results <- NULL

tictoc::tic("starting")

for (i in 1:10) {
  train <- vfold_data$splits[[i]] %>%
    analysis() %>%
    prep_titanic() %>%
    mice(maxit = 50, printFlag = FALSE)

  test <- vfold_data$splits[[i]] %>%
    assessment() %>%
    prep_titanic() %>%
    mice(maxit = 50, printFlag = FALSE)

  results_i <- mapply(
    fit_predict_error,
    mtry = params_test$mtry,
    trees = params_test$trees,
    min_n = params_test$min_n,
    MoreArgs = list(
      train = train,
      test = test,
      trained_recipe = trained_recipe
    )) %>%
    t() %>%
    as.data.frame() %>%
    mutate(fold = i)

  results_i_df <- data.frame(matrix(unlist(results_i), ncol = length(results_i), byrow = F))

  names(results_i_df) <- names(results_i)

  if (is.null(results)) {
    results <- results_i_df
  } else {
    results <- rbind(results, results_i_df)
  }
}

tictoc::toc()

results %>% group_by(mtry, trees, min_n) %>% summarise(min = min(error), median = median(error), mean = mean(error), max = max(error)) %>% arrange(mean)
```



Let's impute those observations by fitting a classification tree using the `parsnip` package.
`parsnip` is a tidy R package which aims to provide a standard API to different
model fitting packages.  The flow is to call the model type 
(e.g. `parsnip::logistic_reg()`), set the algorithm used to fit the model
(e.g. `parsnip::set_engine("rpart", ...)`) (passing package-specific arguments
through the elipses), and fit the model (`parsnip::fit(formula = , data = )`).
The output is a a `parsnip` object (a list `PN`), but you can access the output as if it was
created by the engine by accessing the `fit` element of the object, `PN$fit`.


## Model fit

# https://www.r-bloggers.com/how-to-use-recipes-package-from-tidymodels-for-one-hot-encoding-%F0%9F%9B%A0/ 
# https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c (parsnip walkthrough)
# https://stats.stackexchange.com/questions/228553/perform-random-forest-after-multiple-imputation-with-mice
# https://www.brodrigues.co/blog/2018-11-25-tidy_cv/ (hyperparameter tuning)


```{r}
# i <- 1
# # for (i in 1:5) {
#   imputed_set <- complete(train_imputed, i) %>%
#     mutate(Survived = as.factor(Survived))
#   train_test <- initial_split(imputed_set, prop = 0.8)
#   random_forest <- rand_forest(mode = "classification") %>%
#     set_engine("ranger") %>%
#     fit(Survived ~ . - TicketNumber, data = imputed_set)
#   predictions <- random_forest %>%
#     predict(new_data = complete(test_imputed, 1)) %>%
#     bind_cols(complete(test_imputed, 1) %>% select(PassengerId))
# # }
```



## Including Plots



