---
title: "titanic"
author: "ZackBarry"
date: "8/17/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load libraries.
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
library(DataExplorer)
library(mice)
library(parsnip) # API for rpart() and others, install_github("tidymodels/parsnip")
library(recipes)
library(ranger)
library(rsample)

complete <- mice::complete

# Read in data.
train <- read_csv("Data/titanic/train.csv")
test <- read_csv("Data/titanic/test.csv")
```

## Explore the data using DataExplorer

First, let's see what type of data we're dealing with:
```{r}
plot_intro(train)
```
The majority of the columns contain continuous data and 79.5% of the
rows have at least one missing value. Let's check which columns are
missing data:
```{r}
DataExplorer::plot_missing(train)
```
The majority of the `Cabin` observations are missing, so we will drop
it from consideration for now.  We will impute the missing values for `Embarked` and `Age` below.

Finally, let's get a sense of the distribution of our categorical and
continuous data.
```{r}
DataExplorer::plot_bar(train)
```
The response variable, `Survived`, is well balanced, and each of `Sex`
and `Embarked` have a small set of values.  Since `Name` and `Ticket`
have so many categories we will look into grouping their values when
we do feature selection below.

Next, the continuous data:
```{r}
plot_histogram(train)
```
We see that `Pclass` should be treated as categorical data.
`SibSp` and `Parch` could be binned into `SmallFamily`, `MediumFamily`, and `LargeFamily`, and it may be helpful to bin `Fare`.
`PassengerId` seems unlikely to have any relationship with whether or not that passenger survived. 
Let's check the class-specific distribution of `PassengerId`:
```{r}
ggplot(train, aes(x = PassengerId)) + 
  geom_histogram() + 
  facet_wrap(~Survived)
```
It looks like we can safely drop `PassengerId`.
```{r}
train <- select(train, -PassengerId)
```


## Mutate data

Before imputing the missing values for `Embarked` and `Age`, we will
look at grouping `Name` and `Ticket`.
```{r}
head(train$Name)
```
It looks like each name is of the form `Last, Title. First...`. Two options
present themselves: 1) Extract passenger titles and group accordingly, 
2) Extract last names and match families together.  We will start by examining
the titles.

Use `stringr::str_match()` to extract each title, assuming each title is located after a comma and is ended by a period.
```{r}
train$Title <- str_match(train$Name, ",\\s?([a-zA-Z\\s]+).")[, 2]
train <- select(train, -Name)

plot_bar(train$Title)
```
We will keep `Mr`, `Miss`, `Mrs`, `Master` as is -- the others will be joined to one of the former based on gender; if the title is indicative of a profession, that person will be grouped as `titled`.
```{r}
train <- train %>%
  mutate(Title = tolower(Title)) %>%
  mutate(Title = ifelse(str_detect(Title, "dr|rev|major|col|capt|jonkheer"), "titled",
                        ifelse(str_detect(Title, "miss|mlle|ms|lady"), "miss",
                               ifelse(str_detect(Title, "mrs|mme|countess"), "mrs", 
                                      ifelse(str_detect(Title, "mr|don|sir|master"), "mr",
                                                        "unknown")))))

plot_bar(select(train, Title))
```

Now we can group `Ticket`. The logic behind this grouping is that decreasing the
variance of `Ticket` will reduce the risk of overfitting the model to the test 
data.  Of course, the trade of is that the bias will increase so we'll need to
perform some form of cross-validation to see if the binning is an improvement.
To support this need we'll create a seperate column `TicketBinned` and compare model
performance with it included as the ticket variable or `TicketNumber` as the ticket
variable.  This comparison will be done in the feature selection section.

Some tickets numbersare preceeded by letters, but only
230 of the observations have this extra information:
```{r}
train %>%
  mutate(TicketType = as.numeric(Ticket)) %>%
  filter(is.na(TicketType)) %>% 
  select(Ticket)
```
We will extract the numbers and work with them only.
```{r}
train$TicketNumber <- as.numeric(str_extract(train$Ticket, "[0-9]+$"))

train[is.na(train$TicketNumber),]
```
4 passengers had tickets which did not include numbers -- we will fill in their
ticket value with the average ticket value.
```{r}
train <- train %>%
  mutate(TicketNumber = ifelse(is.na(TicketNumber), mean(train$TicketNumber, na.rm = T), TicketNumber)) %>%
  select(-Ticket)
```

Now, let's determine how to bin `TicketNumber` by looking at a histogram of the
values:
```{r}
train %>%
  ggplot(aes(x = TicketNumber)) +
  geom_histogram()
```
We clearly have a group of tickets with very high values, but it is
difficult to see the distrubution of the the lower value
tickets. Let's exclude the larger ticket values for the next histogram:
```{r}
train %>%
  filter(TicketNumber <= 1e6) %>%
  ggplot(aes(x = TicketNumber)) +
  geom_histogram()
```
No we see that there is a group of ticket values for each interval
from $[i\times 10^5, (i+1)\times 10^5)$, $0\leq i\leq 3$.
```{r}
train <- mutate(train, TicketBinned = round(TicketNumber / 1e5, 0))

count(train, TicketBinned)
```

Lastly, we will use the `SibSp` and `Parch` columns to infer the size of a 
passenger's family.  The logic here is that an individual traveling alone may
have a higher survival chance since they would not be responsible for any 
others.  Large families may have a worse survival chance.  Recall that
`SipSp` is the number of siblings/spouses aboard the Titanic and `Parch` is
the number of parents/children aboard.

```{r}
train <- train %>%
  mutate(
    Singleton = ifelse(SibSp == 0 & Parch == 0, 1, 0),
    Small_Family = ifelse(0 < SibSp + Parch & SibSp + Parch <= 3, 1, 0),
    Large_Family = ifelse(3 < SibSp + Parch, 1, 0)
  )
```

## Handle missing data

Since 77.1% of the `Cabin` observations are missing, we will drop it:
```{r}
train <- drop_columns(train, "Cabin")
```

`Embarked` is missing in 2 observations and `Age` is missing
in 177. We'll simply replace the missing `Embarked` values with the 
most often observed value; `Age` we will impute with the `MICE` package.
```{r}
train$Embarked[is.na(train$Embarked)] <- count(train, Embarked, sort = T)[1,]$Embarked
```

Before using the `MICE` package, we will encode the categorical data in the training set - otherwise those predictors will not be used for filling in the missing data.
To do this, we will use the `recipes` package.
This package streamlines the process by which data is prepped for data
analysis.
```{r}
dummy_recipe <- recipe(Survived ~ ., data = train) %>%
  step_dummy(Embarked, Title) %>%
  prep(training = train, retain = T)

summary(dummy_recipe)
```
The `recipe()` step specifies which variables are predictors and which
are responses for the provided data set.
`step_dummy()` converts the indicted character or factor variables into
binary model terms. 
Finally, `prep()` generates the metadata to actually do the data preparation.
Specifying `retain = T` allows us to prepare (apply) the recipe without
resupplying the data set. This is only helpful if the original data set
used to train the recipe is the same data to be processed.
Since we set this parameter, we can call `juice()` to create the
processed data.
```{r}
train_encoded <- juice(dummy_recipe)
glimpse(train_encoded)
```
Instead of the variable `Title` with 4 responses, `mr`, `mrs`, `titled`,
and `miss`, our data now has three variables `Title_mr`, `Title_mrs`, and
`Title_titled`. If an observation had a `Title` value of `mr`, `mrs`, or
`titled`, the respective `Title_x` has a value of `1`. If an observation
had a `Title` value of `miss`, each `Title_x` is `0`. Similarly for `Embarked`.
```{r}
train_imputed <- mice(data = train_encoded, maxit = 50)
head(train_imputed$imp$Age)
```


## Model training

Before training our Random Forest model, we'll combine all of the preprocessing 
steps above (including `Age` imputation) into a recipe so that we can quickly
prepare subsets of the training data for cross validation.
```{r}
prep_titanic <- function(data) {
  
  # Extract information from unique variables.
  data <- data %>%
    mutate(
      Title = str_match(Name, ",\\s?([a-zA-Z\\s]+).")[, 2],
      Title = tolower(Title), 
      Title = ifelse(str_detect(Title, "dr|rev|major|col|capt|jonkheer"), "titled",
                          ifelse(str_detect(Title, "miss|mlle|ms|lady"), "miss",
                                 ifelse(str_detect(Title, "mrs|mme|countess"), "mrs", 
                                        ifelse(str_detect(Title, "mr|don|sir|master"), "mr",
                                                          "unknown")))),
      TicketNumber = as.numeric(str_extract(Ticket, "[0-9]+$"))
   )
  
  # Apply simple imputations and fill in missing dependent features.
  data <- data %>%
    mutate(
      TicketNumber = ifelse(is.na(TicketNumber), mean(TicketNumber, na.rm = T), TicketNumber),
      TicketBinned = round(TicketNumber / 1e5, 0),
      Embarked = ifelse(is.na(Embarked), count(., Embarked, sort = T)[1,]$Embarked, Embarked)
    ) %>%
    mutate(
      Singleton = ifelse(SibSp == 0 & Parch == 0, 1, 0),
      Small_Family = ifelse(0 < SibSp + Parch & SibSp + Parch <= 3, 1, 0),
      Large_Family = ifelse(3 < SibSp + Parch, 1, 0)
    )
  
  # Keep only a subset of the predictor variables.
  data <- data %>%
    select(
      PassengerId,
      Survived,
      Pclass,
      Sex,
      Age,
      SibSp,
      Parch,
      Fare,
      Embarked,
      Title,
      TicketBinned,
      Singleton,
      Small_Family,
      Large_Family
    )
}

impute_titanic <- function(data, trained_recipe) {
  # Create dummy variables for factor columns.
  #   Note: the training step is only important to do outside of the loop if 
  #         steps in the recipe have the potential to change based on the data
  #         set.  An example would be selecting a column to remove based on 
  #         near-zero variance.  In this case, we are simply creating dummy 
  #         variables so the recipe can be trained and juiced within this
  #         preproccessing function while treating all data sets consistently.
  data <- bake(trained_recipe, data)
  
  # Impute 'Age' using MICE.
  mice(data, maxit = 50, printFlag = FALSE)
}
```

Do do cross-validation, we'll use the `rsample` package and its functions
`vfold_cv`, `analysis` and `assessment`.  `vfold_cv` is used to divide a 
data set into $v$ "folds" of equal size.  For 10-fold cv, each fold is 
approximately $1/10$ the size of the original data set.  The relative
compliment of each fold is used to train the model; an error statistic such
as RMSE is calculated by applying that model to the hold out fold.
To access a training set, `analysis()` is used; to access a hold out set, 
`assessment()` is used.



```{r}
mice_rf <- function(train_imputed, mtry, trees, min_n) {
  # train_imputed: A mice object containing train_imputed$m imputed data sets.
  
  models <- list()
  
  for (i in 1:train_imputed$m) {
    train_imputed_i <- complete(train_imputed, i) %>%
      mutate(Survived = as.factor(Survived))
    
    random_forest_i <- rand_forest(mode = "classification", mtry = mtry, trees = trees, min_n = min_n) %>%
      set_engine("ranger") %>%
      fit(Survived ~ . - TicketNumber - PassengerId, data = train_imputed_i)
    
    models[[i]] <- random_forest_i
  }
  
  return(models)
}

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

ranked_choice <- function(test, models) {
  # test: A single data set, already preprocessed with a column "id".
  # models: A list of models which can be used via predict().
  
  # returns:  id | predicted
  
  predictions <- NULL
  
  for (i in 1:length(models)) {
    
    predictions_i <- models[[i]] %>%
      predict(new_data = test) %>%
      bind_cols(test %>% select(PassengerId)) %>%
      rename(predicted = .pred_class)
    
    if (is.null(predictions)) {
      predictions <- predictions_i
    } else {
      predictions <- rbind(predictions, predictions_i)
    }
    
  }
  
  # predict() returns a factor column instead of a numeric one; convert back
  # before calling Mode()
  predictions %>%
    mutate(predicted = as.numeric(levels(predicted))[predicted]) %>%
    group_by(PassengerId) %>%
    summarise(predicted = Mode(predicted))
}

# trees: 10 - 100
err_rand_forest <- function(test_imputed, models) {
  # cv_data: An object from rsample from which the training set can be retrieved
  #          via analysis(cv_data) and the test set via assessment(cv_data).
  
  result <- NULL
  
  for (i in 1:test_imputed$m) {
    test_i <- complete(test_imputed, i) 
    result_i <- ranked_choice(test_i, models)
    
    if (is.null(result)) {
      result <- result_i
    } else {
      result <- rbind(result, result_i)
    }
  }
  
  ranked_choice_result <- result %>%
    group_by(PassengerId) %>%
    summarise(predicted = Mode(predicted)) 
  
  true_result <- complete(test, 1)
  
  mean(ranked_choice_result$predicted != true_result$Survived)
}

fit_predict_error <- function(train_imputed, test_imputed, mtry, trees, min_n) {
  
  models <- mice_rf(train_imputed, mtry, trees, min_n)
  
  error <- err_rand_forest(test_imputed, models)
  
  print(paste(error, mtry, trees, min_n))
  
  return(data.frame(error = error, mtry = mtry, trees = trees, min_n = min_n))
}
```

```{r}
train_prepped <- prep_titanic(train)

trained_recipe <- recipe(Survived ~ ., data = train_prepped) %>%
    step_dummy(Embarked, Title) %>%
    prep(training = train_prepped)

test_recipe <- train_prepped %>%
  mutate(Pclass = as.factor(Pclass)) %>%
  recipe(Survived ~ ., data = .) %>%
  step_dummy(Embarked, Title, Sex, Pclass) %>%
  prep(training = mutate(train_prepped, Pclass = as.factor(Pclass)))

vfold_data <- vfold_cv(train, v = 10)

params <- tidyr::crossing(
  mtry = seq(1, 8),
  trees = seq(50, 500, 50),
  min_n = seq(5, 50, by = 5)
)

params_test <- tidyr::crossing(
  mtry = seq(4, 5),
  trees = seq(150, 200, 50),
  min_n = seq(10, 20, by = 5)
)

results <- NULL
 
tictoc::tic("starting")

for (i in 1:10) {
  train <- vfold_data$splits[[i]] %>%
    analysis() %>%
    prep_titanic() %>%
    impute_titanic(trained_recipe)
  
  test <- vfold_data$splits[[i]] %>%
    assessment() %>%
    prep_titanic() %>%
    impute_titanic(trained_recipe)
  
  results_i <- mapply(
    fit_predict_error, 
    mtry = params$mtry, 
    trees = params$trees, 
    min_n = params$min_n, 
    MoreArgs = list(
      train = train, 
      test = test)
    ) %>%
    t() %>%
    as.data.frame() %>%
    mutate(fold = i)
  
  results_i_df <- data.frame(matrix(unlist(results_i), ncol = length(results_i), byrow = F))
  
  names(results_i_df) <- names(results_i)
  
  if (is.null(results)) {
    results <- results_i_df
  } else {
    results <- rbind(results, results_i_df)
  }
}

tictoc::toc()

results %>% group_by(mtry, trees, min_n) %>% summarise(min = min(error), median = median(error), mean = mean(error), max = max(error)) %>% arrange(mean)
```



Let's impute those observations by fitting a classification tree using the `parsnip` package.
`parsnip` is a tidy R package which aims to provide a standard API to different
model fitting packages.  The flow is to call the model type 
(e.g. `parsnip::logistic_reg()`), set the algorithm used to fit the model
(e.g. `parsnip::set_engine("rpart", ...)`) (passing package-specific arguments
through the elipses), and fit the model (`parsnip::fit(formula = , data = )`).
The output is a a `parsnip` object (a list `PN`), but you can access the output as if it was
created by the engine by accessing the `fit` element of the object, `PN$fit`.


## Model fit

# https://www.r-bloggers.com/how-to-use-recipes-package-from-tidymodels-for-one-hot-encoding-%F0%9F%9B%A0/ 
# https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c (parsnip walkthrough)
# https://stats.stackexchange.com/questions/228553/perform-random-forest-after-multiple-imputation-with-mice
# https://www.brodrigues.co/blog/2018-11-25-tidy_cv/ (hyperparameter tuning)


```{r}
i <- 1
# for (i in 1:5) {
  imputed_set <- complete(train_imputed, i) %>%
    mutate(Survived = as.factor(Survived))
  train_test <- initial_split(imputed_set, prop = 0.8)
  random_forest <- rand_forest(mode = "classification") %>%
    set_engine("ranger") %>%
    fit(Survived ~ . - TicketNumber, data = imputed_set)
  predictions <- random_forest %>%
    predict(new_data = complete(test_imputed, 1)) %>%
    bind_cols(complete(test_imputed, 1) %>% select(PassengerId))
# }
```



## Including Plots



